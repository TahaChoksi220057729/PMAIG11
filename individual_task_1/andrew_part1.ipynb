{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c175d4d6132787b7",
   "metadata": {},
   "source": [
    "### Download dataset from Kaggle, fashion_mnist\n",
    "\n",
    "todo: explain why we choose to use fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-30T12:42:44.925963Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n",
      "(10000, 785)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "training_set = pd.read_csv('Dataset/fashion_data/fashion-mnist_train.csv')\n",
    "test_set = pd.read_csv('Dataset/fashion_data/fashion-mnist_test.csv')\n",
    "\n",
    "m, n = training_set.shape\n",
    "\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)\n",
    "\n",
    "training_set = np.array(training_set)\n",
    "test_set = np.array(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0306a4ea9e7d442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T12:41:50.930074Z",
     "start_time": "2024-11-30T12:41:50.927427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000)\n",
      "(60000,)\n",
      "(784, 10000)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# X is pixels, y is labels\n",
    "\n",
    "test_set = test_set.T\n",
    "\n",
    "y_test = test_set[0]\n",
    "X_test = test_set[1:]\n",
    "X_test = X_test / 255\n",
    "\n",
    "training_set = training_set.T\n",
    "\n",
    "y_train = training_set[0]\n",
    "X_train = training_set[1:]\n",
    "\n",
    "X_train = X_train / 255\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3059ba8-f8be-4583-a14f-7690f5fafdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    \n",
    "    def __init__(self, X_train, y_train, learning_rate, epochs, dropout_rate=0.2, dropout=False):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout = dropout    \n",
    "        \n",
    "    def init_param(self):\n",
    "        w1 = np.random.rand(10, 784) * 0.01\n",
    "        b1 = np.random.rand(10, 1)\n",
    "        w2 = np.random.rand(10, 10) * 0.01\n",
    "        b2 = np.random.rand(10, 1)\n",
    "        \n",
    "        return w1, b1, w2, b2\n",
    "        \n",
    "    # activation functions and its derivatives\n",
    "    def ReLU(self, x):\n",
    "        t= x * (x > 0)\n",
    "        return t\n",
    "    \n",
    "    def ReLU_derivative(self, x):\n",
    "        return (x >= 0) * 1\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        s=1/(1+np.exp(-x))\n",
    "        return s\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        s=1/(1+np.exp(-x))\n",
    "        ds=s*(1-s)  \n",
    "        return ds\n",
    "        \n",
    "    def softmax(self, x):\n",
    "        return np.exp(x)/sum(np.exp(x))\n",
    "        def one_hot(Y):\n",
    "            one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "            one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "            one_hot_Y = one_hot_Y.T\n",
    "            return one_hot_Y  \n",
    "\n",
    "    def forward_prop(self, w1, b1, w2, b2, X, dropout_rate=0.2, dropout=True):\n",
    "    \n",
    "        z1 = w1.dot(X) + b1\n",
    "        a1 = self.ReLU(z1)\n",
    "    \n",
    "        if dropout:\n",
    "            dropout_mask = (np.random.rand(*a1.shape) < dropout_rate) / dropout_rate\n",
    "            a1 = a1 * dropout_mask\n",
    "        else:\n",
    "            dropout_mask = None\n",
    "        \n",
    "        z2 = w2.dot(a1) + b2\n",
    "        a2 = self.softmax(z2)\n",
    "        \n",
    "        return z1, a1, z2, a2, dropout_mask\n",
    "        \n",
    "\n",
    "    def one_hot(self, Y):\n",
    "        one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "        one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "        one_hot_Y = one_hot_Y.T\n",
    "        return one_hot_Y  \n",
    "    \n",
    "    def neg_log_likelihood(self, y, y_hat):\n",
    "        return -1/len(y) * np.sum(np.sum(y * np.log(y_hat)))\n",
    "        \n",
    "\n",
    "    def back_prop(self, z1, a1, z2, a2, w2, X, Y, dropout_mask):\n",
    "        \n",
    "        one_hot_y = self.one_hot(Y)\n",
    "        \n",
    "        dz2 = a2 - one_hot_y\n",
    "        \n",
    "        dw2 = 1/m * dz2.dot(a1.T)\n",
    "        db2 = 1/m * np.sum(dz2)\n",
    "        \n",
    "        dz1 = w2.T.dot(dz2) * self.ReLU_derivative(z1)\n",
    "    \n",
    "        dz1 = dz1 * dropout_mask if dropout_mask is not None else dz1\n",
    "        \n",
    "        dw1 = 1 / m * dz1.dot(X.T)\n",
    "        db1 = 1 / m * np.sum(dz1)\n",
    "        \n",
    "        return dw1, db1, dw2, db2\n",
    "\n",
    "    def update_param(self, W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "        W1 = W1 - alpha * dW1\n",
    "        b1 = b1 - alpha * db1    \n",
    "        W2 = W2 - alpha * dW2  \n",
    "        b2 = b2 - alpha * db2    \n",
    "        return W1, b1, W2, b2\n",
    "        \n",
    "    \n",
    "    def get_predictions(self, A2):\n",
    "        return np.argmax(A2, 0)\n",
    "        \n",
    "\n",
    "    def get_accuracy(self, predictions, Y):\n",
    "        print(predictions, Y)\n",
    "        return np.sum(predictions == Y) / Y.size\n",
    "        \n",
    "    \n",
    "    def gradient_descent(self, X, Y, alpha, iterations, dropout_rate=0.2, dropout=False):\n",
    "    \n",
    "        w1, b1, w2, b2 = self.init_param()\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            z1, a1, z2, a2, dropout_mask = self.forward_prop(w1, b1, w2, b2, X, dropout_rate, dropout=True)\n",
    "            dW1, db1, dW2, db2 = self.back_prop(z1, a1, z2, a2, w2, X, Y, dropout_mask)\n",
    "            w1, b1, w2, b2 = self.update_param(w1, b1, w2, b2, dW1, db1, dW2, db2, alpha)\n",
    "            if i % 10 == 0:\n",
    "                print(\"Iteration: \", i)\n",
    "                predictions = self.get_predictions(a2)\n",
    "                print(self.get_accuracy(predictions, Y))\n",
    "            \n",
    "        return w1, b1, w2, b2\n",
    "\n",
    "    def train(self):\n",
    "        self.gradient_descent(self.X_train, self.y_train, self.learning_rate, self.epochs, self.dropout_rate, self.dropout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63de6a03-a077-49eb-9806-264321f67892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[8 8 8 ... 8 0 8] [2 9 6 ... 8 8 7]\n",
      "0.09886666666666667\n",
      "Iteration:  10\n",
      "[2 8 2 ... 2 8 8] [2 9 6 ... 8 8 7]\n",
      "0.107\n",
      "Iteration:  20\n",
      "[4 8 4 ... 0 4 0] [2 9 6 ... 8 8 7]\n",
      "0.10963333333333333\n",
      "Iteration:  30\n",
      "[0 8 0 ... 2 0 8] [2 9 6 ... 8 8 7]\n",
      "0.10995\n",
      "Iteration:  40\n",
      "[0 8 8 ... 8 0 8] [2 9 6 ... 8 8 7]\n",
      "0.11403333333333333\n",
      "Iteration:  50\n",
      "[1 8 4 ... 0 0 8] [2 9 6 ... 8 8 7]\n",
      "0.12271666666666667\n",
      "Iteration:  60\n",
      "[2 8 1 ... 2 9 8] [2 9 6 ... 8 8 7]\n",
      "0.1485\n",
      "Iteration:  70\n",
      "[0 8 0 ... 0 8 9] [2 9 6 ... 8 8 7]\n",
      "0.15995\n",
      "Iteration:  80\n",
      "[0 8 2 ... 0 8 8] [2 9 6 ... 8 8 7]\n",
      "0.16981666666666667\n",
      "Iteration:  90\n",
      "[0 9 2 ... 0 8 8] [2 9 6 ... 8 8 7]\n",
      "0.17751666666666666\n",
      "Iteration:  100\n",
      "[0 8 0 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.18903333333333333\n",
      "Iteration:  110\n",
      "[4 8 8 ... 0 0 8] [2 9 6 ... 8 8 7]\n",
      "0.19333333333333333\n",
      "Iteration:  120\n",
      "[8 8 2 ... 0 8 9] [2 9 6 ... 8 8 7]\n",
      "0.19743333333333332\n",
      "Iteration:  130\n",
      "[2 8 0 ... 2 8 8] [2 9 6 ... 8 8 7]\n",
      "0.20381666666666667\n",
      "Iteration:  140\n",
      "[8 9 4 ... 8 9 9] [2 9 6 ... 8 8 7]\n",
      "0.20646666666666666\n",
      "Iteration:  150\n",
      "[8 8 2 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.208\n",
      "Iteration:  160\n",
      "[2 8 4 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.21086666666666667\n",
      "Iteration:  170\n",
      "[9 8 4 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.2124\n",
      "Iteration:  180\n",
      "[0 8 8 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.21738333333333335\n",
      "Iteration:  190\n",
      "[2 8 0 ... 9 0 8] [2 9 6 ... 8 8 7]\n",
      "0.21635\n",
      "Iteration:  200\n",
      "[0 9 4 ... 2 0 8] [2 9 6 ... 8 8 7]\n",
      "0.21825\n",
      "Iteration:  210\n",
      "[0 9 4 ... 2 8 8] [2 9 6 ... 8 8 7]\n",
      "0.22025\n",
      "Iteration:  220\n",
      "[2 8 8 ... 9 8 8] [2 9 6 ... 8 8 7]\n",
      "0.22341666666666668\n",
      "Iteration:  230\n",
      "[2 8 8 ... 0 8 8] [2 9 6 ... 8 8 7]\n",
      "0.22521666666666668\n",
      "Iteration:  240\n",
      "[0 8 8 ... 9 0 8] [2 9 6 ... 8 8 7]\n",
      "0.22453333333333333\n",
      "Iteration:  250\n",
      "[8 9 2 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.2264\n",
      "Iteration:  260\n",
      "[9 8 8 ... 8 8 9] [2 9 6 ... 8 8 7]\n",
      "0.22951666666666667\n",
      "Iteration:  270\n",
      "[8 9 4 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.23318333333333333\n",
      "Iteration:  280\n",
      "[8 8 4 ... 2 8 8] [2 9 6 ... 8 8 7]\n",
      "0.23598333333333332\n",
      "Iteration:  290\n",
      "[8 8 4 ... 2 8 8] [2 9 6 ... 8 8 7]\n",
      "0.23521666666666666\n",
      "Iteration:  300\n",
      "[9 8 4 ... 2 8 8] [2 9 6 ... 8 8 7]\n",
      "0.23315\n",
      "Iteration:  310\n",
      "[0 8 0 ... 8 9 8] [2 9 6 ... 8 8 7]\n",
      "0.24065\n",
      "Iteration:  320\n",
      "[2 8 8 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.23916666666666667\n",
      "Iteration:  330\n",
      "[2 8 8 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.24108333333333334\n",
      "Iteration:  340\n",
      "[9 9 8 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.24046666666666666\n",
      "Iteration:  350\n",
      "[8 9 8 ... 2 8 8] [2 9 6 ... 8 8 7]\n",
      "0.24116666666666667\n",
      "Iteration:  360\n",
      "[2 9 8 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.24175\n",
      "Iteration:  370\n",
      "[2 8 4 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.24336666666666668\n",
      "Iteration:  380\n",
      "[2 8 8 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.24161666666666667\n",
      "Iteration:  390\n",
      "[2 8 1 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.24445\n",
      "Iteration:  400\n",
      "[2 8 0 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.2432\n",
      "Iteration:  410\n",
      "[0 8 2 ... 8 8 9] [2 9 6 ... 8 8 7]\n",
      "0.24801666666666666\n",
      "Iteration:  420\n",
      "[8 8 4 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.24458333333333335\n",
      "Iteration:  430\n",
      "[8 9 4 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.2437\n",
      "Iteration:  440\n",
      "[8 8 1 ... 8 2 9] [2 9 6 ... 8 8 7]\n",
      "0.24521666666666667\n",
      "Iteration:  450\n",
      "[2 8 4 ... 9 9 8] [2 9 6 ... 8 8 7]\n",
      "0.24548333333333333\n",
      "Iteration:  460\n",
      "[4 8 0 ... 8 2 8] [2 9 6 ... 8 8 7]\n",
      "0.24601666666666666\n",
      "Iteration:  470\n",
      "[8 8 1 ... 2 8 9] [2 9 6 ... 8 8 7]\n",
      "0.24665\n",
      "Iteration:  480\n",
      "[9 8 8 ... 8 9 8] [2 9 6 ... 8 8 7]\n",
      "0.2476\n",
      "Iteration:  490\n",
      "[8 8 4 ... 8 8 8] [2 9 6 ... 8 8 7]\n",
      "0.24755\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(X_train, y_train, 0.1, 500, 0.2, False)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d5318-e55b-4a74-b6ac-61e566b0cf20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
