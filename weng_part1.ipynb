{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Download dataset from Kaggle, fashion_mnist\n",
    "\n",
    "todo: explain why we choose to use fashion_mnist"
   ],
   "id": "c175d4d6132787b7"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-03T14:23:27.841541Z",
     "start_time": "2024-12-03T14:23:25.787474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "training_set = pd.read_csv('Dataset/fashion_data/fashion-mnist_train.csv')\n",
    "test_set = pd.read_csv('Dataset/fashion_data/fashion-mnist_test.csv')\n",
    "\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n",
      "(10000, 785)\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "perform data cleaning",
   "id": "99bd1df81b11ee9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:23:27.861436Z",
     "start_time": "2024-12-03T14:23:27.853962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# X is pixels, y is labels\n",
    "y_train = training_set.iloc[:, 0].to_numpy()\n",
    "X_train = training_set.iloc[:, 1:].to_numpy()\n",
    "y_test = test_set.iloc[:, 0].to_numpy()\n",
    "X_test = test_set.iloc[:, 1:].to_numpy()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ],
   "id": "e0306a4ea9e7d442",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:23:27.946853Z",
     "start_time": "2024-12-03T14:23:27.897357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#visualising one image\n",
    "\n",
    "# choosing the first image\n",
    "image_array = X_train[0]\n",
    "label = y_train[0]\n",
    "\n",
    "# reshape 784 to 28x28\n",
    "image_array = image_array.reshape(28, 28)\n",
    "\n",
    "# plotting the image\n",
    "plt.imshow(image_array, cmap='gray')\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ],
   "id": "c3ad543f1f410c0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:23:28.083830Z",
     "start_time": "2024-12-03T14:23:27.962074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# rescaling the pixel values down to values between 0 - 1 for efficiency of neural network\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ],
   "id": "e19cba663018fe9a",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:23:28.103069Z",
     "start_time": "2024-12-03T14:23:28.097497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# one hot encoding for labels\n",
    "\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)\n",
    "\n",
    "print(y_train.shape)\n"
   ],
   "id": "97de46df7fa7c311",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:23:28.121492Z",
     "start_time": "2024-12-03T14:23:28.119514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# architecture of the neural network\n",
    "input_nodes = X_train.shape[1]\n",
    "hidden_nodes = 128\n",
    "output_nodes = 10"
   ],
   "id": "c71c15c75dd284c0",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:46:24.401313Z",
     "start_time": "2024-12-03T14:46:24.391407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# activation functions and its derivatives\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.x_copy = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x_copy = x\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        if self.x_copy > 0:\n",
    "            return 1 * dout\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.x_copy = None\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x_copy = x\n",
    "        # consider clipping to prevent under / overflow\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return self.sigmoid(self.x_copy) * (1 - self.sigmoid(self.x_copy)) * dout\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "    def __init__(self, crossEntropy=False):\n",
    "        self.x_copy = None\n",
    "        self.cross_entropy = crossEntropy\n",
    "\n",
    "    def softmax(self, x):\n",
    "        return np.exp(x) / np.exp(x).sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x_copy = x\n",
    "        return self.softmax(x)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        if self.cross_entropy:\n",
    "            return dout\n",
    "        else:\n",
    "            # reshaping shape (m,) to (m,1) by doing [:, None] to allow broadcasting\n",
    "            return self.softmax(self.x_copy) * (dout - (dout * self.softmax(self.x_copy)).sum(axis=1)[:, None])\n",
    "\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self, input_num, output_num):\n",
    "        self.db = None\n",
    "        self.dw = None\n",
    "        self.rng = np.random.default_rng(42)\n",
    "        self.weights = self.rng.normal(size=(input_num, output_num)) * np.sqrt(2 / input_num)\n",
    "        self.bias = np.zeros((1, output_num))\n",
    "        self.X_copy = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X_copy = X\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \"\"\"\n",
    "        Backward pass for the linear layer.\n",
    "        Parameters:\n",
    "            dout: Gradient of the loss with respect to the output (batch_size, output_num)\n",
    "        Returns:\n",
    "            dx: Gradient of the loss with respect to the input X (batch_size, input_num)\n",
    "        \"\"\"\n",
    "        # Gradient with respect to weights\n",
    "        dw = np.dot(self.X_copy.T, dout)  # Shape: (input_num, output_num)\n",
    "\n",
    "        # Gradient with respect to biases\n",
    "        db = np.sum(dout, axis=0)  # Shape: (1, output_num)\n",
    "\n",
    "        # Gradient with respect to inputs\n",
    "        dx = np.dot(dout, self.weights.T)  # Shape: (batch_size, input_num)\n",
    "\n",
    "        # Save gradients for weight and bias updates\n",
    "        self.dw = dw\n",
    "        self.db = db\n",
    "\n",
    "        return dx\n",
    "\n",
    "\n",
    "class CrossEntropy:\n",
    "    def __init__(self, softmax=False):\n",
    "        self.y_pred_copy = None\n",
    "        self.softmax = softmax\n",
    "\n",
    "    def forward(self, y, y_pred):\n",
    "        self.y_pred_copy = y_pred.clip(min=1e-8, max=None)\n",
    "        return -np.mean(np.sum(y * np.log(self.y_pred_copy)))\n",
    "\n",
    "    def backward(self, y):\n",
    "        if self.softmax:\n",
    "            return self.y_pred_copy - y\n",
    "        # -y / y_pred / y.shape[0]\n",
    "        return np.where(y == 1, - y / (self.y_pred_copy + 1e-15) / y.shape[0], 0)\n"
   ],
   "id": "2246ea3f1eb50fb8",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:46:25.246252Z",
     "start_time": "2024-12-03T14:46:25.243224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def create_weights(rows, cols):\n",
    "#     # generate random numbers from normal distribution\n",
    "#     return np.random.randn(rows, cols)"
   ],
   "id": "2a372ab7ed84b56e",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:46:25.540646Z",
     "start_time": "2024-12-03T14:46:25.538821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# w1 = create_weights(input_nodes, hidden_nodes)\n",
    "# b1 = np.zeros((w1.shape[0], 1))\n",
    "# \n",
    "# w2 = create_weights(hidden_nodes, output_nodes)\n",
    "# b2 = np.zeros((w2.shape[0], 1))\n",
    "# \n",
    "# print(w1.shape, b1.shape, w2.shape, b2.shape)"
   ],
   "id": "c611da5a67745c68",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:46:26.189347Z",
     "start_time": "2024-12-03T14:46:26.185698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, loss_fn, learning_rate):\n",
    "        self.layers = layers\n",
    "        self.loss_fn = loss_fn\n",
    "        self.learning_rate = learning_rate\n",
    "        return\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def loss(self, y, y_pred):\n",
    "        return self.loss_fn.forward(y, y_pred)\n",
    "\n",
    "    def backward(self, y):\n",
    "        grad = self.loss_fn.backward(y)\n",
    "        for i in range(len(self.layers)-1,-1,-1):\n",
    "            grad = self.layers[i].backward(grad)\n",
    "\n",
    "    def update(self, X, y):\n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        return\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        return"
   ],
   "id": "9a078cf45c4abbdb",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:46:27.265092Z",
     "start_time": "2024-12-03T14:46:27.202884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = NeuralNetwork([Linear(X_train.shape[1], 100), ReLU(), Linear(100, 10), Softmax(crossEntropy=True)],\n",
    "                      CrossEntropy(softmax=True), 0.01)\n",
    "\n",
    "y_pred = model.forward(X_train)\n",
    "model.loss(y_train, y_pred)"
   ],
   "id": "cd4faca7dc18eb51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(15325.75856937663)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:46:28.368400Z",
     "start_time": "2024-12-03T14:46:28.327706Z"
    }
   },
   "cell_type": "code",
   "source": "model.backward(y_train)",
   "id": "ef2a8599ae3473dd",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[81], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[79], line 20\u001B[0m, in \u001B[0;36mNeuralNetwork.backward\u001B[0;34m(self, y)\u001B[0m\n\u001B[1;32m     18\u001B[0m grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn\u001B[38;5;241m.\u001B[39mbackward(y)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers)\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m---> 20\u001B[0m     grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[76], line 11\u001B[0m, in \u001B[0;36mReLU.backward\u001B[0;34m(self, dout)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackward\u001B[39m(\u001B[38;5;28mself\u001B[39m, dout):\n\u001B[0;32m---> 11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx_copy \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m*\u001B[39m dout\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5c7636553c68faea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
