{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Download dataset from Kaggle, fashion_mnist\n",
    "\n",
    "todo: explain why we choose to use fashion_mnist"
   ],
   "id": "c175d4d6132787b7"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-10T15:53:07.288952Z",
     "start_time": "2024-12-10T15:53:05.069881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "training_set = pd.read_csv('Dataset/fashion_data/fashion-mnist_train.csv')\n",
    "test_set = pd.read_csv('Dataset/fashion_data/fashion-mnist_test.csv')\n",
    "\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n",
      "(10000, 785)\n"
     ]
    }
   ],
   "execution_count": 328
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Separate into X and y sets\n",
    "One hot encode y_train and t_test"
   ],
   "id": "99bd1df81b11ee9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:53:07.304895Z",
     "start_time": "2024-12-10T15:53:07.301930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # One hot encode\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)"
   ],
   "id": "d5f6b4a07a57bad8",
   "outputs": [],
   "execution_count": 329
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:53:07.698438Z",
     "start_time": "2024-12-10T15:53:07.325650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# X is pixels, y is labels\n",
    "\n",
    "X_train, y_train = to_xy(training_set, 'label')\n",
    "X_test, y_test = to_xy(test_set, 'label')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(y_test[0])"
   ],
   "id": "e0306a4ea9e7d442",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "execution_count": 330
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:53:07.763345Z",
     "start_time": "2024-12-10T15:53:07.713380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#visualising one image\n",
    "\n",
    "# choosing the first image\n",
    "image_array = X_train[0]\n",
    "label = y_train[0]\n",
    "\n",
    "# reshape 784 to 28x28\n",
    "image_array = image_array.reshape(28, 28)\n",
    "\n",
    "# plotting the image\n",
    "plt.imshow(image_array, cmap='gray')\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ],
   "id": "c3ad543f1f410c0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 331
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:53:07.816588Z",
     "start_time": "2024-12-10T15:53:07.776694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# rescaling the pixel values down to values between 0 - 1 for efficiency of neural network\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "# X_test = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)"
   ],
   "id": "e19cba663018fe9a",
   "outputs": [],
   "execution_count": 332
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:53:07.837212Z",
     "start_time": "2024-12-10T15:53:07.829748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# activation functions and its derivatives\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.x_copy = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x_copy = x\n",
    "        out = np.maximum(0, x)\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        #dout in: (60000, 15)\n",
    "        #x_copy: (60000, 15)\n",
    "        dout = dout * (self.x_copy > 0)\n",
    "        #dout out: (60000, 15)\n",
    "        return dout\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.x_copy = None\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        x = np.clip(x, -500, 500)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x_copy = x\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return self.sigmoid(self.x_copy) * (1 - self.sigmoid(self.x_copy)) * dout\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "    def __init__(self, crossEntropy=False):\n",
    "        self.x_copy = None\n",
    "        self.cross_entropy = crossEntropy\n",
    "\n",
    "    def softmax(self, x):\n",
    "        stable_exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        y_prob = stable_exp_x / np.sum(stable_exp_x, axis=1, keepdims=True)\n",
    "        return y_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x_copy = x\n",
    "        out = self.softmax(x)\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        if self.cross_entropy:\n",
    "            return dout\n",
    "        else:\n",
    "            softmax_output = self.softmax(self.x_copy)\n",
    "            return softmax_output * (dout - (dout * softmax_output).sum(axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self, input_num, output_num, weight_init=\"he\"):\n",
    "        self.db = None\n",
    "        self.dw = None\n",
    "        self.rng = np.random.default_rng(42)\n",
    "        # initialise weights with Xavier initialisation\n",
    "        if weight_init == \"he\":\n",
    "            self.weights = self.rng.normal(size=(input_num, output_num)) * np.sqrt(2 / input_num)\n",
    "        elif weight_init == \"xavier\":\n",
    "            self.weights = self.rng.normal(size=(input_num, output_num)) * np.sqrt(1 / input_num)\n",
    "        self.bias = np.zeros((1, output_num))\n",
    "        self.X_copy = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X_copy = X\n",
    "        out = np.dot(X, self.weights) + self.bias\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        # Gradient with respect to weights\n",
    "        dw = np.dot(self.X_copy.T, dout)  # Shape: (input_num, output_num)\n",
    "        \n",
    "        # Gradient with respect to biases\n",
    "        db = np.sum(dout, axis=0, keepdims=True)  # Shape: (1, output_num)\n",
    "\n",
    "        # Gradient with respect to inputs\n",
    "        dx = np.dot(dout, self.weights.T)  # Shape: (batch_size, input_num)\n",
    "\n",
    "        # Save gradients for weight and bias updates\n",
    "        self.dw = dw\n",
    "        self.db = db\n",
    "        \n",
    "\n",
    "        return dx\n",
    "\n",
    "    def update_weights(self, learning_rate, l2_reg=1e-4):\n",
    "        assert self.dw is not None and self.db is not None, \"Gradients must be computed before updating weights\"\n",
    "        self.weights -= learning_rate * (self.dw + l2_reg * self.weights)\n",
    "        self.bias -= learning_rate * self.db\n",
    "\n",
    "\n",
    "class CrossEntropy:\n",
    "    def __init__(self, softmax=False):\n",
    "        self.y_pred_copy = None\n",
    "        self.softmax = softmax\n",
    "\n",
    "    def forward(self, y, y_pred):\n",
    "        self.y_pred_copy = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "        loss = -np.mean(np.sum(y * np.log(self.y_pred_copy), axis=1)) # axis = 1 to sum across classes\n",
    "        return loss \n",
    "\n",
    "    def backward(self, y):\n",
    "        if self.softmax:\n",
    "            return self.y_pred_copy - y\n",
    "        # -y / y_pred / y.shape[0]\n",
    "        return np.where(y == 1, - y / (self.y_pred_copy + 1e-15) / y.shape[0], 0)"
   ],
   "id": "2246ea3f1eb50fb8",
   "outputs": [],
   "execution_count": 333
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:53:07.854554Z",
     "start_time": "2024-12-10T15:53:07.850497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, loss_fn, learning_rate):\n",
    "        self.layers = layers\n",
    "        self.loss_fn = loss_fn\n",
    "        self.learning_rate = learning_rate\n",
    "        return\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, y, y_pred):\n",
    "        return self.loss_fn.forward(y, y_pred)\n",
    "\n",
    "    def backward(self, y_train):\n",
    "        grad = self.loss_fn.backward(y_train)\n",
    "        for i in range(len(self.layers) - 1, -1, -1):\n",
    "            grad = self.layers[i].backward(grad)\n",
    "\n",
    "    def update(self):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Linear):\n",
    "                layer.update_weights(self.learning_rate)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        correct_predictions = np.argmax(y_pred, axis=1) == np.argmax(y_test, axis=1)\n",
    "        accuracy = np.mean(correct_predictions)\n",
    "        return accuracy\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=100):\n",
    "        loss_hist = []\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(X_train)\n",
    "            loss = self.loss(y_train, y_pred)\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "            loss_hist.append(loss)\n",
    "            self.backward(y_train)\n",
    "            self.update()\n",
    "        return loss_hist"
   ],
   "id": "9a078cf45c4abbdb",
   "outputs": [],
   "execution_count": 334
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:53:07.869729Z",
     "start_time": "2024-12-10T15:53:07.867734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_loss(loss_hist):\n",
    "    plt.plot(loss_hist)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "id": "3dbf0b8ed880df79",
   "outputs": [],
   "execution_count": 335
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initialising a model",
   "id": "a6a8a13bc8316e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:53:07.893233Z",
     "start_time": "2024-12-10T15:53:07.884144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = NeuralNetwork(\n",
    "    [\n",
    "        Linear(X_train.shape[1], 400),\n",
    "        ReLU(),\n",
    "        Linear(400, 100),\n",
    "        ReLU(),\n",
    "        Linear(100,50 ),\n",
    "        ReLU(),\n",
    "        Linear(50, 10,weight_init=\"xavier\"),\n",
    "        Softmax(crossEntropy=True)\n",
    "    ],\n",
    "    CrossEntropy(softmax=True), \n",
    "    0.001)"
   ],
   "id": "cd4faca7dc18eb51",
   "outputs": [],
   "execution_count": 336
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training model & plotting loss",
   "id": "d25a65dadd8579f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:53:33.654912Z",
     "start_time": "2024-12-10T15:53:07.908768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_sample = X_train\n",
    "y_train_sample = y_train\n",
    "loss_hist = model.train(X_train_sample, y_train_sample, epochs=100)\n",
    "plot_loss(loss_hist)"
   ],
   "id": "27240361d33a2686",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.361940337013778\n",
      "Epoch: 10, Loss: 29.71413119425427\n",
      "Epoch: 20, Loss: 15.835275345796425\n",
      "Epoch: 30, Loss: 14.248398670853382\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[337], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m X_train_sample \u001B[38;5;241m=\u001B[39m X_train\n\u001B[1;32m      2\u001B[0m y_train_sample \u001B[38;5;241m=\u001B[39m y_train\n\u001B[0;32m----> 3\u001B[0m loss_hist \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_sample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_sample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m plot_loss(loss_hist)\n",
      "Cell \u001B[0;32mIn[334], line 38\u001B[0m, in \u001B[0;36mNeuralNetwork.train\u001B[0;34m(self, X_train, y_train, epochs)\u001B[0m\n\u001B[1;32m     36\u001B[0m loss_hist \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m---> 38\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss(y_train, y_pred)\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "Cell \u001B[0;32mIn[334], line 10\u001B[0m, in \u001B[0;36mNeuralNetwork.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 10\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "Cell \u001B[0;32mIn[333], line 73\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX_copy \u001B[38;5;241m=\u001B[39m X\n\u001B[0;32m---> 73\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 337
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate model",
   "id": "9c7d429774e69b3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:53:33.726459Z",
     "start_time": "2024-12-10T15:49:26.949976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "acc = model.evaluate(X_test, y_test)\n",
    "print(acc)"
   ],
   "id": "ef2a8599ae3473dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "execution_count": 326
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:53:33.726847Z",
     "start_time": "2024-12-10T15:49:27.083299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y = y_test[:5]\n",
    "predicted_classes = np.argmax(y_pred, axis=1)\n",
    "true_classes = np.argmax(y_test[:5], axis=1)\n",
    "print(\"Predicted classes:\", predicted_classes)\n",
    "print(\"True classes:\", true_classes)"
   ],
   "id": "5c7636553c68faea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [4 4 4 4 4]\n",
      "True classes: [0 1 2 2 3]\n"
     ]
    }
   ],
   "execution_count": 327
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:53:33.726902Z",
     "start_time": "2024-12-10T15:49:27.107891Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4619fb5d9e8f5834",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
